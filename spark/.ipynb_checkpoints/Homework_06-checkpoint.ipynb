{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc95f6c-2fb0-48c4-9028-9365f57f3004",
   "metadata": {},
   "source": [
    "## Qusetion 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42301cc0-eb06-49fb-a79b-531037d218f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2076005e-1d48-4da9-aee1-60f638468353",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "26/02/25 22:21:34 WARN Utils: Your hostname, codespaces-6ec39f, resolves to a loopback address: 127.0.0.1; using 10.0.1.147 instead (on interface eth0)\n",
      "26/02/25 22:21:34 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/02/25 22:21:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "26/02/25 22:21:37 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "26/02/25 22:21:37 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ceefc69-10eb-491c-889f-f9fdd7b4c981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.1.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ad51e6-ae60-4dd0-bd26-407bab1501bf",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59787c74-c733-493a-87c2-93c4f51142b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2026-02-25 22:27:54--  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-11.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 52.85.97.61, 52.85.97.44, 52.85.97.194, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|52.85.97.61|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 71134255 (68M) [binary/octet-stream]\n",
      "Saving to: ‘yellow_tripdata_2025-11.parquet’\n",
      "\n",
      "yellow_tripdata_202 100%[===================>]  67.84M  18.8MB/s    in 3.6s    \n",
      "\n",
      "2026-02-25 22:27:58 (18.8 MB/s) - ‘yellow_tripdata_2025-11.parquet’ saved [71134255/71134255]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-11.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24f00a38-9075-49c5-a4a0-2c181ac8bea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"yellow_tripdata_2025-11.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c697faa-4e5d-461b-89a9-c23a9ed80e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82e0a83e-cfb8-4449-8029-7984bb8f6010",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df.write.mode(\"overwrite\").parquet(\"yellow_2025_11_repartitioned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4611759-1f97-4f24-a2dd-01f0ff093fc8",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4153bdf-954b-4914-8bdd-c1dc5aab9e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- Airport_fee: double (nullable = true)\n",
      " |-- cbd_congestion_fee: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3f090db-4ec0-4880-91b2-a955ed347311",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"yellow_trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71e48310-8576-4e5c-9223-dbdd7c725ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:=============================>                             (1 + 1) / 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|trip_count|\n",
      "+----------+\n",
      "|    162604|\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "result = spark.sql(\"\"\"\n",
    "    SELECT COUNT(*) AS trip_count\n",
    "    FROM yellow_trips\n",
    "    WHERE DATE(tpep_pickup_datetime) = '2025-11-15'\n",
    "\"\"\")\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f5f3b2-7f42-4aca-851c-690a49a18cd2",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a87463c-b9ed-4c2d-81a6-7ba13893ec8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:=============================>                            (2 + 2) / 4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|longest_trip_hours|\n",
      "+------------------+\n",
      "|         90.646667|\n",
      "+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        MAX((UNIX_TIMESTAMP(tpep_dropoff_datetime) - \n",
    "             UNIX_TIMESTAMP(tpep_pickup_datetime)) / 3600.0) AS longest_trip_hours\n",
    "    FROM yellow_trips\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c2b3c0-a899-411b-accf-b1cddfe0f826",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "295e82cd-3f48-42fc-afa7-cff7bb6161e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2026-02-25 22:36:23--  https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 52.85.97.61, 52.85.97.13, 52.85.97.194, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|52.85.97.61|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12331 (12K) [text/csv]\n",
      "Saving to: ‘taxi_zone_lookup.csv.1’\n",
      "\n",
      "taxi_zone_lookup.cs 100%[===================>]  12.04K  --.-KB/s    in 0s      \n",
      "\n",
      "2026-02-25 22:36:23 (1.13 GB/s) - ‘taxi_zone_lookup.csv.1’ saved [12331/12331]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35cc65bb-aa21-4e72-a259-0d780df1ed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read.option(\"header\", \"true\") \\\n",
    "    .csv(\"taxi_zone_lookup.csv\")\n",
    "\n",
    "df_zones.createOrReplaceTempView(\"zones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5957bb96-aca0-4ae8-af67-3d029523d798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LocationID: string (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zones.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fb16bc6-10d3-47f8-b7c2-d703e7c20081",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:===========================================>              (3 + 1) / 4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|                Zone|trip_count|\n",
      "+--------------------+----------+\n",
      "|Governor's Island...|         1|\n",
      "+--------------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        z.Zone,\n",
    "        COUNT(*) AS trip_count\n",
    "    FROM yellow_trips y\n",
    "    JOIN zones z\n",
    "        ON y.PULocationID = z.LocationID\n",
    "    GROUP BY z.Zone\n",
    "    ORDER BY trip_count ASC\n",
    "    LIMIT 1\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2739c2-82db-436a-83ef-96f6add6419d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
